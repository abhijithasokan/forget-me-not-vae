{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6476faa9",
   "metadata": {},
   "source": [
    "# Toy experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddeb5003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../')\n",
    "\n",
    "import forget_me_not "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb55481a",
   "metadata": {},
   "source": [
    "### Set the parameters here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbebf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset parameters\n",
    "TRAIN_FRACTION = 0.9\n",
    "EVAL_FRACTION = 0.1\n",
    "NUM_SAMPLES_PER_CLASS = 20000\n",
    "GAUSSIAN_MIXTURE_DIM = 16\n",
    "GAUSSIAN_MIXTURE_CLASSES = 10\n",
    "\n",
    "# Model hyperparameters\n",
    "LATENT_DIM = 4\n",
    "BETA = 20.0\n",
    "\n",
    "# Training settings\n",
    "LEARNING_RATE = 0.0002\n",
    "BATCH_SIZE = 1024\n",
    "MAX_NUM_EPOCHS = 12"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f2e4fa7",
   "metadata": {},
   "source": [
    "## Gaussian mixture dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ff0dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from forget_me_not.datasets.gaussian_mixture import GaussianMixtureDataModule\n",
    "dm = GaussianMixtureDataModule(\n",
    "    n_samples=NUM_SAMPLES_PER_CLASS, \n",
    "    n_features=GAUSSIAN_MIXTURE_DIM, \n",
    "    n_classes=GAUSSIAN_MIXTURE_CLASSES, \n",
    "    variance_scale=(0, 8), \n",
    "    mean_scale=(0, 40),\n",
    "    seed=1,\n",
    "    train_fraction=TRAIN_FRACTION, \n",
    "    eval_fraction=EVAL_FRACTION,\n",
    ")\n",
    "dm.plot_train()\n",
    "dm.plot_test()\n",
    "dm.plot_eval()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "81382e4a",
   "metadata": {},
   "source": [
    "## Training $\\beta$-VAE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffa9e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from forget_me_not.models.vae import VAE\n",
    "from forget_me_not.training.train_beta_vae import BetaVAEModule, train\n",
    "vae_model = VAE(dim=GAUSSIAN_MIXTURE_DIM, hidden_dim=32, latent_dim=LATENT_DIM)\n",
    "model = BetaVAEModule(vae_model, loss='vanilla-beta-vae', beta=BETA, learning_rate=LEARNING_RATE)\n",
    "\n",
    "\n",
    "val_data_loader = dm.val_dataloader(batch_size=BATCH_SIZE)\n",
    "train_data_loader = dm.train_dataloader(batch_size=BATCH_SIZE)\n",
    "\n",
    "\n",
    "train(model, train_data_loader, val_data_loader, num_epochs=30, accelerator='cpu', enable_progress_bar=True, early_stop=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "470703c9",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7149ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from forget_me_not import metrics \n",
    "\n",
    "test_data_loader = dm.test_dataloader(batch_size=BATCH_SIZE)\n",
    "nll = metrics.compute_negative_log_likelihood(vae_model, test_data_loader, dim=GAUSSIAN_MIXTURE_DIM, num_importance_sampling=500)\n",
    "print(f\"Negative log likelihood: {nll}\")\n",
    "\n",
    "au = metrics.active_units(vae_model, test_data_loader)\n",
    "print(f\"Active units: {au} out of {LATENT_DIM}\")\n",
    "\n",
    "mi = metrics.mutual_information(vae_model, test_data_loader, num_samples=1000)\n",
    "print(f\"Mutual information: {mi}\")\n",
    "\n",
    "dc = metrics.compute_density_and_coverage(vae_model, test_data_loader, num_samples=len(test_data_loader.dataset), nearest_k = 5)\n",
    "print(f\"Density: {dc['density']}, Coverage: {dc['coverage']}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ad8acce",
   "metadata": {},
   "source": [
    "## PCA on encodings of the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5f7e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def plot_latent_representation_2d(vae_model, samples, labels):\n",
    "    vae_model.eval()\n",
    "    with torch.no_grad():\n",
    "        latent_rep = vae_model.get_latent_representation(samples, deterministic=False)\n",
    "        \n",
    "    pca = PCA(n_components=2)\n",
    "    reduced_rep = pca.fit_transform(latent_rep)\n",
    "    \n",
    "    data = reduced_rep\n",
    "    plt.scatter(data[:, 0], data[:, 1], c=labels.unsqueeze(1), marker='.')\n",
    "    plt.show()\n",
    "\n",
    "def plot_reconstruction_2d(vae_model, samples, labels):\n",
    "    vae_model.eval()\n",
    "    with torch.no_grad():\n",
    "        _, recon, *_ = vae_model.forward(samples, deterministic=False)\n",
    "        \n",
    "    pca = PCA(n_components=2)\n",
    "    reduced_rep = pca.fit_transform(recon)\n",
    "    \n",
    "    data = reduced_rep\n",
    "    plt.scatter(data[:, 0], data[:, 1], c=labels.unsqueeze(1), marker='.')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "test_data_loader = dm.test_dataloader(batch_size=None)\n",
    "vae_model.eval()\n",
    "with torch.no_grad():\n",
    "    data, labels = next(iter(test_data_loader))\n",
    "    plot_latent_representation_2d(vae_model, data, labels)\n",
    "    plot_reconstruction_2d(vae_model, data, labels)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ec6526f",
   "metadata": {},
   "source": [
    "# Self critic VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ced13fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from forget_me_not.models.vae import VAE\n",
    "from forget_me_not.training.train_beta_vae import BetaVAEModule, train\n",
    "vae_model_sc = VAE(dim=GAUSSIAN_MIXTURE_DIM, hidden_dim=32, latent_dim=LATENT_DIM)\n",
    "model_sc = BetaVAEModule(vae_model_sc, loss='self-critic', beta=10.0, learning_rate=LEARNING_RATE)\n",
    "\n",
    "\n",
    "val_data_loader = dm.val_dataloader(batch_size=BATCH_SIZE)\n",
    "train_data_loader = dm.train_dataloader(batch_size=BATCH_SIZE)\n",
    "\n",
    "\n",
    "train(model_sc, train_data_loader, val_data_loader, num_epochs=20, accelerator='cpu', enable_progress_bar=True, early_stop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e7dbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from forget_me_not import metrics \n",
    "\n",
    "test_data_loader = dm.test_dataloader(batch_size=BATCH_SIZE)\n",
    "nll = metrics.compute_negative_log_likelihood(vae_model_sc, test_data_loader, dim=GAUSSIAN_MIXTURE_DIM, num_importance_sampling=500)\n",
    "print(f\"Negative log likelihood: {nll}\")\n",
    "\n",
    "au = metrics.active_units(vae_model_sc, test_data_loader)\n",
    "print(f\"Active units: {au} out of {LATENT_DIM}\")\n",
    "\n",
    "mi = metrics.mutual_information(vae_model_sc, test_data_loader, num_samples=1000)\n",
    "print(f\"Mutual information: {mi}\")\n",
    "\n",
    "dc = metrics.compute_density_and_coverage(vae_model_sc, test_data_loader, num_samples=len(test_data_loader.dataset), nearest_k = 5)\n",
    "print(f\"Density: {dc['density']}, Coverage: {dc['coverage']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c49f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def plot_latent_representation_2d(vae_model, samples, labels):\n",
    "    vae_model.eval()\n",
    "    with torch.no_grad():\n",
    "        latent_rep = vae_model.get_latent_representation(samples, deterministic=False)\n",
    "        \n",
    "    pca = PCA(n_components=2)\n",
    "    reduced_rep = pca.fit_transform(latent_rep)\n",
    "    \n",
    "    data = reduced_rep\n",
    "    plt.scatter(data[:, 0], data[:, 1], c=labels.unsqueeze(1), marker='.')\n",
    "    plt.xlim(-1.0, 1.0)\n",
    "    plt.ylim(-1.0, 1.0)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "test_data_loader = dm.test_dataloader(batch_size=None)\n",
    "vae_model_sc.eval()\n",
    "with torch.no_grad():\n",
    "    data, labels = next(iter(test_data_loader))\n",
    "    plot_latent_representation_2d(vae_model_sc, data, labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
